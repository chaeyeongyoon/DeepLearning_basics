{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig with Non-Normalized Input and small learningrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0 Cost:  2455327000000.0 \n",
      "Prediction:\n",
      " [[-1104436.2]\n",
      " [-2224343. ]\n",
      " [-1749606.6]\n",
      " [-1226179.4]\n",
      " [-1445287.1]\n",
      " [-1457459.5]\n",
      " [-1335740.5]\n",
      " [-1700924.5]]\n",
      "1 Cost:  2.69762e+27 \n",
      "Prediction:\n",
      " [[3.6637149e+13]\n",
      " [7.3754336e+13]\n",
      " [5.8019879e+13]\n",
      " [4.0671629e+13]\n",
      " [4.7933685e+13]\n",
      " [4.8337135e+13]\n",
      " [4.4302659e+13]\n",
      " [5.6406091e+13]]\n",
      "2 Cost:  inf \n",
      "Prediction:\n",
      " [[-1.2143879e+21]\n",
      " [-2.4446870e+21]\n",
      " [-1.9231472e+21]\n",
      " [-1.3481161e+21]\n",
      " [-1.5888267e+21]\n",
      " [-1.6021996e+21]\n",
      " [-1.4684714e+21]\n",
      " [-1.8696560e+21]]\n",
      "3 Cost:  inf \n",
      "Prediction:\n",
      " [[4.0252522e+28]\n",
      " [8.1032447e+28]\n",
      " [6.3745308e+28]\n",
      " [4.4685124e+28]\n",
      " [5.2663807e+28]\n",
      " [5.3107068e+28]\n",
      " [4.8674466e+28]\n",
      " [6.1972267e+28]]\n",
      "4 Cost:  inf \n",
      "Prediction:\n",
      " [[-1.3342243e+36]\n",
      " [-2.6859301e+36]\n",
      " [-2.1129243e+36]\n",
      " [-1.4811488e+36]\n",
      " [-1.7456130e+36]\n",
      " [-1.7603054e+36]\n",
      " [-1.6133809e+36]\n",
      " [-2.0541546e+36]]\n",
      "5 Cost:  inf \n",
      "Prediction:\n",
      " [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "6 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "# Very small Learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매우 작은 learning rate 에도 불구하고 nan발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normallize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
      " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
      "0 Cost:  0.7992051 \n",
      "Prediction:\n",
      " [[ 0.47259712]\n",
      " [ 0.23193526]\n",
      " [-0.15399647]\n",
      " [-0.5640317 ]\n",
      " [-0.3167944 ]\n",
      " [-0.42378223]\n",
      " [-1.0409808 ]\n",
      " [-1.0878552 ]]\n",
      "1 Cost:  0.799157 \n",
      "Prediction:\n",
      " [[ 0.47263503]\n",
      " [ 0.23197353]\n",
      " [-0.15396416]\n",
      " [-0.564006  ]\n",
      " [-0.3167646 ]\n",
      " [-0.42375332]\n",
      " [-1.0409598 ]\n",
      " [-1.0878341 ]]\n",
      "2 Cost:  0.7991088 \n",
      "Prediction:\n",
      " [[ 0.47267294]\n",
      " [ 0.23201168]\n",
      " [-0.15393174]\n",
      " [-0.5639803 ]\n",
      " [-0.3167348 ]\n",
      " [-0.4237244 ]\n",
      " [-1.0409387 ]\n",
      " [-1.0878129 ]]\n",
      "3 Cost:  0.7990605 \n",
      "Prediction:\n",
      " [[ 0.47271085]\n",
      " [ 0.23205006]\n",
      " [-0.15389931]\n",
      " [-0.5639546 ]\n",
      " [-0.31670493]\n",
      " [-0.42369545]\n",
      " [-1.0409176 ]\n",
      " [-1.0877918 ]]\n",
      "4 Cost:  0.79901236 \n",
      "Prediction:\n",
      " [[ 0.47274876]\n",
      " [ 0.23208821]\n",
      " [-0.153867  ]\n",
      " [-0.56392884]\n",
      " [-0.3166752 ]\n",
      " [-0.42366642]\n",
      " [-1.0408967 ]\n",
      " [-1.0877707 ]]\n",
      "5 Cost:  0.7989642 \n",
      "Prediction:\n",
      " [[ 0.47278666]\n",
      " [ 0.23212636]\n",
      " [-0.1538347 ]\n",
      " [-0.5639031 ]\n",
      " [-0.31664538]\n",
      " [-0.4236375 ]\n",
      " [-1.0408756 ]\n",
      " [-1.0877496 ]]\n",
      "6 Cost:  0.7989161 \n",
      "Prediction:\n",
      " [[ 0.47282457]\n",
      " [ 0.23216474]\n",
      " [-0.15380228]\n",
      " [-0.5638774 ]\n",
      " [-0.31661558]\n",
      " [-0.42360854]\n",
      " [-1.0408546 ]\n",
      " [-1.0877285 ]]\n",
      "7 Cost:  0.7988678 \n",
      "Prediction:\n",
      " [[ 0.47286248]\n",
      " [ 0.232203  ]\n",
      " [-0.15376985]\n",
      " [-0.56385165]\n",
      " [-0.31658572]\n",
      " [-0.42357957]\n",
      " [-1.0408335 ]\n",
      " [-1.0877073 ]]\n",
      "8 Cost:  0.7988196 \n",
      "Prediction:\n",
      " [[ 0.4729004 ]\n",
      " [ 0.23224127]\n",
      " [-0.15373755]\n",
      " [-0.5638259 ]\n",
      " [-0.31655598]\n",
      " [-0.4235506 ]\n",
      " [-1.0408125 ]\n",
      " [-1.0876862 ]]\n",
      "9 Cost:  0.7987715 \n",
      "Prediction:\n",
      " [[ 0.4729383 ]\n",
      " [ 0.23227942]\n",
      " [-0.15370524]\n",
      " [-0.56380016]\n",
      " [-0.31652611]\n",
      " [-0.42352164]\n",
      " [-1.0407914 ]\n",
      " [-1.0876651 ]]\n",
      "10 Cost:  0.7987232 \n",
      "Prediction:\n",
      " [[ 0.4729762 ]\n",
      " [ 0.23231769]\n",
      " [-0.15367281]\n",
      " [-0.56377447]\n",
      " [-0.31649637]\n",
      " [-0.42349273]\n",
      " [-1.0407703 ]\n",
      " [-1.0876439 ]]\n",
      "11 Cost:  0.798675 \n",
      "Prediction:\n",
      " [[ 0.47301412]\n",
      " [ 0.23235595]\n",
      " [-0.15364039]\n",
      " [-0.5637487 ]\n",
      " [-0.31646645]\n",
      " [-0.42346376]\n",
      " [-1.0407493 ]\n",
      " [-1.0876228 ]]\n",
      "12 Cost:  0.79862696 \n",
      "Prediction:\n",
      " [[ 0.47305202]\n",
      " [ 0.23239422]\n",
      " [-0.15360808]\n",
      " [-0.563723  ]\n",
      " [-0.31643677]\n",
      " [-0.4234348 ]\n",
      " [-1.0407283 ]\n",
      " [-1.0876017 ]]\n",
      "13 Cost:  0.7985788 \n",
      "Prediction:\n",
      " [[ 0.4730898 ]\n",
      " [ 0.23243248]\n",
      " [-0.15357578]\n",
      " [-0.56369734]\n",
      " [-0.31640697]\n",
      " [-0.4234059 ]\n",
      " [-1.0407072 ]\n",
      " [-1.0875806 ]]\n",
      "14 Cost:  0.79853064 \n",
      "Prediction:\n",
      " [[ 0.4731276 ]\n",
      " [ 0.23247051]\n",
      " [-0.15354347]\n",
      " [-0.5636716 ]\n",
      " [-0.31637716]\n",
      " [-0.42337692]\n",
      " [-1.0406861 ]\n",
      " [-1.0875595 ]]\n",
      "15 Cost:  0.7984825 \n",
      "Prediction:\n",
      " [[ 0.4731655 ]\n",
      " [ 0.23250878]\n",
      " [-0.15351105]\n",
      " [-0.5636459 ]\n",
      " [-0.31634736]\n",
      " [-0.42334807]\n",
      " [-1.0406651 ]\n",
      " [-1.0875382 ]]\n",
      "16 Cost:  0.7984343 \n",
      "Prediction:\n",
      " [[ 0.47320342]\n",
      " [ 0.23254704]\n",
      " [-0.15347874]\n",
      " [-0.56362015]\n",
      " [-0.31631762]\n",
      " [-0.4233191 ]\n",
      " [-1.040644  ]\n",
      " [-1.0875171 ]]\n",
      "17 Cost:  0.7983862 \n",
      "Prediction:\n",
      " [[ 0.4732412 ]\n",
      " [ 0.23258519]\n",
      " [-0.15344644]\n",
      " [-0.56359446]\n",
      " [-0.31628788]\n",
      " [-0.42329013]\n",
      " [-1.0406231 ]\n",
      " [-1.087496  ]]\n",
      "18 Cost:  0.7983382 \n",
      "Prediction:\n",
      " [[ 0.473279  ]\n",
      " [ 0.23262334]\n",
      " [-0.15341413]\n",
      " [-0.56356883]\n",
      " [-0.316258  ]\n",
      " [-0.42326128]\n",
      " [-1.040602  ]\n",
      " [-1.087475  ]]\n",
      "19 Cost:  0.79829 \n",
      "Prediction:\n",
      " [[ 0.4733169 ]\n",
      " [ 0.2326616 ]\n",
      " [-0.1533817 ]\n",
      " [-0.5635431 ]\n",
      " [-0.31622827]\n",
      " [-0.42323232]\n",
      " [-1.040581  ]\n",
      " [-1.0874538 ]]\n",
      "20 Cost:  0.79824185 \n",
      "Prediction:\n",
      " [[ 0.4733547 ]\n",
      " [ 0.23269987]\n",
      " [-0.1533494 ]\n",
      " [-0.5635174 ]\n",
      " [-0.31619853]\n",
      " [-0.42320347]\n",
      " [-1.0405599 ]\n",
      " [-1.0874326 ]]\n",
      "21 Cost:  0.79819375 \n",
      "Prediction:\n",
      " [[ 0.4733925 ]\n",
      " [ 0.2327379 ]\n",
      " [-0.1533171 ]\n",
      " [-0.5634917 ]\n",
      " [-0.31616879]\n",
      " [-0.4231745 ]\n",
      " [-1.0405388 ]\n",
      " [-1.0874115 ]]\n",
      "22 Cost:  0.79814565 \n",
      "Prediction:\n",
      " [[ 0.4734304 ]\n",
      " [ 0.23277617]\n",
      " [-0.15328479]\n",
      " [-0.56346595]\n",
      " [-0.31613898]\n",
      " [-0.42314553]\n",
      " [-1.0405178 ]\n",
      " [-1.0873904 ]]\n",
      "23 Cost:  0.7980976 \n",
      "Prediction:\n",
      " [[ 0.47346818]\n",
      " [ 0.23281431]\n",
      " [-0.15325248]\n",
      " [-0.56344026]\n",
      " [-0.31610924]\n",
      " [-0.42311668]\n",
      " [-1.0404968 ]\n",
      " [-1.0873693 ]]\n",
      "24 Cost:  0.79804945 \n",
      "Prediction:\n",
      " [[ 0.47350597]\n",
      " [ 0.23285246]\n",
      " [-0.15322018]\n",
      " [-0.5634145 ]\n",
      " [-0.3160795 ]\n",
      " [-0.42308772]\n",
      " [-1.0404757 ]\n",
      " [-1.0873481 ]]\n",
      "25 Cost:  0.79800135 \n",
      "Prediction:\n",
      " [[ 0.47354376]\n",
      " [ 0.23289073]\n",
      " [-0.15318787]\n",
      " [-0.5633889 ]\n",
      " [-0.3160497 ]\n",
      " [-0.42305887]\n",
      " [-1.0404546 ]\n",
      " [-1.087327  ]]\n",
      "26 Cost:  0.7979533 \n",
      "Prediction:\n",
      " [[ 0.47358155]\n",
      " [ 0.23292887]\n",
      " [-0.15315557]\n",
      " [-0.5633632 ]\n",
      " [-0.3160199 ]\n",
      " [-0.4230299 ]\n",
      " [-1.0404336 ]\n",
      " [-1.0873059 ]]\n",
      "27 Cost:  0.7979053 \n",
      "Prediction:\n",
      " [[ 0.47361946]\n",
      " [ 0.23296702]\n",
      " [-0.15312326]\n",
      " [-0.5633375 ]\n",
      " [-0.31599015]\n",
      " [-0.423001  ]\n",
      " [-1.0404127 ]\n",
      " [-1.0872848 ]]\n",
      "28 Cost:  0.79785705 \n",
      "Prediction:\n",
      " [[ 0.47365725]\n",
      " [ 0.23300529]\n",
      " [-0.15309083]\n",
      " [-0.5633118 ]\n",
      " [-0.3159604 ]\n",
      " [-0.42297208]\n",
      " [-1.0403916 ]\n",
      " [-1.0872636 ]]\n",
      "29 Cost:  0.797809 \n",
      "Prediction:\n",
      " [[ 0.47369504]\n",
      " [ 0.23304343]\n",
      " [-0.15305865]\n",
      " [-0.56328607]\n",
      " [-0.3159306 ]\n",
      " [-0.42294312]\n",
      " [-1.0403705 ]\n",
      " [-1.0872425 ]]\n",
      "30 Cost:  0.79776096 \n",
      "Prediction:\n",
      " [[ 0.47373295]\n",
      " [ 0.23308158]\n",
      " [-0.15302622]\n",
      " [-0.5632604 ]\n",
      " [-0.31590086]\n",
      " [-0.42291427]\n",
      " [-1.0403495 ]\n",
      " [-1.0872214 ]]\n",
      "31 Cost:  0.7977128 \n",
      "Prediction:\n",
      " [[ 0.47377074]\n",
      " [ 0.23311985]\n",
      " [-0.15299392]\n",
      " [-0.5632347 ]\n",
      " [-0.31587112]\n",
      " [-0.4228853 ]\n",
      " [-1.0403285 ]\n",
      " [-1.0872003 ]]\n",
      "32 Cost:  0.79766476 \n",
      "Prediction:\n",
      " [[ 0.47380853]\n",
      " [ 0.23315799]\n",
      " [-0.15296161]\n",
      " [-0.56320894]\n",
      " [-0.31584132]\n",
      " [-0.4228564 ]\n",
      " [-1.0403074 ]\n",
      " [-1.0871792 ]]\n",
      "33 Cost:  0.7976166 \n",
      "Prediction:\n",
      " [[ 0.47384632]\n",
      " [ 0.23319614]\n",
      " [-0.15292919]\n",
      " [-0.5631833 ]\n",
      " [-0.31581157]\n",
      " [-0.42282754]\n",
      " [-1.0402863 ]\n",
      " [-1.087158  ]]\n",
      "34 Cost:  0.79756856 \n",
      "Prediction:\n",
      " [[ 0.4738841 ]\n",
      " [ 0.2332344 ]\n",
      " [-0.152897  ]\n",
      " [-0.56315756]\n",
      " [-0.31578183]\n",
      " [-0.42279863]\n",
      " [-1.0402653 ]\n",
      " [-1.0871369 ]]\n",
      "35 Cost:  0.7975205 \n",
      "Prediction:\n",
      " [[ 0.473922  ]\n",
      " [ 0.23327255]\n",
      " [-0.15286458]\n",
      " [-0.5631319 ]\n",
      " [-0.31575203]\n",
      " [-0.42276967]\n",
      " [-1.0402443 ]\n",
      " [-1.0871158 ]]\n",
      "36 Cost:  0.79747236 \n",
      "Prediction:\n",
      " [[ 0.4739598 ]\n",
      " [ 0.2333107 ]\n",
      " [-0.15283227]\n",
      " [-0.5631062 ]\n",
      " [-0.31572223]\n",
      " [-0.42274076]\n",
      " [-1.0402232 ]\n",
      " [-1.0870947 ]]\n",
      "37 Cost:  0.7974243 \n",
      "Prediction:\n",
      " [[ 0.4739976 ]\n",
      " [ 0.23334897]\n",
      " [-0.15279996]\n",
      " [-0.56308043]\n",
      " [-0.31569248]\n",
      " [-0.4227118 ]\n",
      " [-1.0402021 ]\n",
      " [-1.0870736 ]]\n",
      "38 Cost:  0.7973762 \n",
      "Prediction:\n",
      " [[ 0.4740355 ]\n",
      " [ 0.23338711]\n",
      " [-0.15276766]\n",
      " [-0.5630548 ]\n",
      " [-0.31566274]\n",
      " [-0.42268294]\n",
      " [-1.0401812 ]\n",
      " [-1.0870523 ]]\n",
      "39 Cost:  0.7973282 \n",
      "Prediction:\n",
      " [[ 0.4740733 ]\n",
      " [ 0.23342526]\n",
      " [-0.15273535]\n",
      " [-0.56302905]\n",
      " [-0.315633  ]\n",
      " [-0.42265397]\n",
      " [-1.0401601 ]\n",
      " [-1.0870312 ]]\n",
      "40 Cost:  0.7972801 \n",
      "Prediction:\n",
      " [[ 0.47411108]\n",
      " [ 0.23346353]\n",
      " [-0.15270305]\n",
      " [-0.5630034 ]\n",
      " [-0.31560326]\n",
      " [-0.42262506]\n",
      " [-1.0401391 ]\n",
      " [-1.0870101 ]]\n",
      "41 Cost:  0.79723203 \n",
      "Prediction:\n",
      " [[ 0.47414887]\n",
      " [ 0.23350167]\n",
      " [-0.15267074]\n",
      " [-0.5629777 ]\n",
      " [-0.31557345]\n",
      " [-0.42259622]\n",
      " [-1.040118  ]\n",
      " [-1.086989  ]]\n",
      "42 Cost:  0.797184 \n",
      "Prediction:\n",
      " [[ 0.47418666]\n",
      " [ 0.23353982]\n",
      " [-0.15263844]\n",
      " [-0.562952  ]\n",
      " [-0.31554365]\n",
      " [-0.42256725]\n",
      " [-1.040097  ]\n",
      " [-1.086968  ]]\n",
      "43 Cost:  0.7971359 \n",
      "Prediction:\n",
      " [[ 0.47422457]\n",
      " [ 0.23357797]\n",
      " [-0.15260613]\n",
      " [-0.5629263 ]\n",
      " [-0.3155139 ]\n",
      " [-0.4225384 ]\n",
      " [-1.0400759 ]\n",
      " [-1.0869467 ]]\n",
      "44 Cost:  0.79708785 \n",
      "Prediction:\n",
      " [[ 0.47426236]\n",
      " [ 0.23361623]\n",
      " [-0.15257382]\n",
      " [-0.56290054]\n",
      " [-0.31548417]\n",
      " [-0.42250943]\n",
      " [-1.0400549 ]\n",
      " [-1.0869256 ]]\n",
      "45 Cost:  0.7970398 \n",
      "Prediction:\n",
      " [[ 0.47430015]\n",
      " [ 0.23365438]\n",
      " [-0.15254152]\n",
      " [-0.5628749 ]\n",
      " [-0.31545436]\n",
      " [-0.42248052]\n",
      " [-1.0400338 ]\n",
      " [-1.0869045 ]]\n",
      "46 Cost:  0.7969917 \n",
      "Prediction:\n",
      " [[ 0.47433805]\n",
      " [ 0.23369265]\n",
      " [-0.15250921]\n",
      " [-0.56284916]\n",
      " [-0.31542456]\n",
      " [-0.42245162]\n",
      " [-1.0400128 ]\n",
      " [-1.0868834 ]]\n",
      "47 Cost:  0.7969436 \n",
      "Prediction:\n",
      " [[ 0.47437584]\n",
      " [ 0.2337308 ]\n",
      " [-0.15247679]\n",
      " [-0.5628235 ]\n",
      " [-0.31539488]\n",
      " [-0.42242265]\n",
      " [-1.0399917 ]\n",
      " [-1.0868622 ]]\n",
      "48 Cost:  0.7968956 \n",
      "Prediction:\n",
      " [[ 0.47441363]\n",
      " [ 0.23376894]\n",
      " [-0.1524446 ]\n",
      " [-0.56279784]\n",
      " [-0.31536508]\n",
      " [-0.4223938 ]\n",
      " [-1.0399706 ]\n",
      " [-1.0868411 ]]\n",
      "49 Cost:  0.7968475 \n",
      "Prediction:\n",
      " [[ 0.47445142]\n",
      " [ 0.2338072 ]\n",
      " [-0.15241218]\n",
      " [-0.5627721 ]\n",
      " [-0.31533533]\n",
      " [-0.42236483]\n",
      " [-1.0399497 ]\n",
      " [-1.08682   ]]\n",
      "50 Cost:  0.79679954 \n",
      "Prediction:\n",
      " [[ 0.4744892 ]\n",
      " [ 0.23384523]\n",
      " [-0.15237987]\n",
      " [-0.5627464 ]\n",
      " [-0.3153056 ]\n",
      " [-0.42233592]\n",
      " [-1.0399287 ]\n",
      " [-1.0867989 ]]\n",
      "51 Cost:  0.7967515 \n",
      "Prediction:\n",
      " [[ 0.47452712]\n",
      " [ 0.2338835 ]\n",
      " [-0.15234756]\n",
      " [-0.5627207 ]\n",
      " [-0.3152758 ]\n",
      " [-0.422307  ]\n",
      " [-1.0399076 ]\n",
      " [-1.0867777 ]]\n",
      "52 Cost:  0.79670334 \n",
      "Prediction:\n",
      " [[ 0.4745649 ]\n",
      " [ 0.23392165]\n",
      " [-0.15231514]\n",
      " [-0.56269497]\n",
      " [-0.315246  ]\n",
      " [-0.4222781 ]\n",
      " [-1.0398865 ]\n",
      " [-1.0867566 ]]\n",
      "53 Cost:  0.79665536 \n",
      "Prediction:\n",
      " [[ 0.4746027 ]\n",
      " [ 0.2339598 ]\n",
      " [-0.15228283]\n",
      " [-0.5626693 ]\n",
      " [-0.31521624]\n",
      " [-0.4222492 ]\n",
      " [-1.0398655 ]\n",
      " [-1.0867355 ]]\n",
      "54 Cost:  0.7966073 \n",
      "Prediction:\n",
      " [[ 0.4746406 ]\n",
      " [ 0.23399806]\n",
      " [-0.15225053]\n",
      " [-0.5626436 ]\n",
      " [-0.3151865 ]\n",
      " [-0.42222023]\n",
      " [-1.0398445 ]\n",
      " [-1.0867144 ]]\n",
      "55 Cost:  0.7965592 \n",
      "Prediction:\n",
      " [[ 0.4746784 ]\n",
      " [ 0.2340362 ]\n",
      " [-0.15221822]\n",
      " [-0.5626179 ]\n",
      " [-0.3151567 ]\n",
      " [-0.42219126]\n",
      " [-1.0398234 ]\n",
      " [-1.0866933 ]]\n",
      "56 Cost:  0.79651123 \n",
      "Prediction:\n",
      " [[ 0.4747162 ]\n",
      " [ 0.23407435]\n",
      " [-0.15218592]\n",
      " [-0.56259227]\n",
      " [-0.31512702]\n",
      " [-0.42216247]\n",
      " [-1.0398023 ]\n",
      " [-1.0866721 ]]\n",
      "57 Cost:  0.79646313 \n",
      "Prediction:\n",
      " [[ 0.47475398]\n",
      " [ 0.23411262]\n",
      " [-0.15215361]\n",
      " [-0.5625665 ]\n",
      " [-0.3150972 ]\n",
      " [-0.4221335 ]\n",
      " [-1.0397813 ]\n",
      " [-1.086651  ]]\n",
      "58 Cost:  0.7964151 \n",
      "Prediction:\n",
      " [[ 0.47479177]\n",
      " [ 0.23415089]\n",
      " [-0.1521213 ]\n",
      " [-0.56254077]\n",
      " [-0.3150674 ]\n",
      " [-0.4221046 ]\n",
      " [-1.0397602 ]\n",
      " [-1.0866299 ]]\n",
      "59 Cost:  0.79636717 \n",
      "Prediction:\n",
      " [[ 0.47482967]\n",
      " [ 0.23418891]\n",
      " [-0.152089  ]\n",
      " [-0.5625151 ]\n",
      " [-0.31503767]\n",
      " [-0.4220757 ]\n",
      " [-1.0397393 ]\n",
      " [-1.0866088 ]]\n",
      "60 Cost:  0.7963191 \n",
      "Prediction:\n",
      " [[ 0.47486746]\n",
      " [ 0.23422718]\n",
      " [-0.1520567 ]\n",
      " [-0.5624894 ]\n",
      " [-0.31500793]\n",
      " [-0.42204678]\n",
      " [-1.0397182 ]\n",
      " [-1.0865877 ]]\n",
      "61 Cost:  0.796271 \n",
      "Prediction:\n",
      " [[ 0.47490525]\n",
      " [ 0.23426533]\n",
      " [-0.15202439]\n",
      " [-0.5624637 ]\n",
      " [-0.31497812]\n",
      " [-0.42201787]\n",
      " [-1.0396972 ]\n",
      " [-1.0865664 ]]\n",
      "62 Cost:  0.7962229 \n",
      "Prediction:\n",
      " [[ 0.47494316]\n",
      " [ 0.23430347]\n",
      " [-0.15199208]\n",
      " [-0.562438  ]\n",
      " [-0.31494832]\n",
      " [-0.42198896]\n",
      " [-1.0396761 ]\n",
      " [-1.0865453 ]]\n",
      "63 Cost:  0.796175 \n",
      "Prediction:\n",
      " [[ 0.47498095]\n",
      " [ 0.23434174]\n",
      " [-0.15195966]\n",
      " [-0.5624123 ]\n",
      " [-0.31491858]\n",
      " [-0.42196   ]\n",
      " [-1.0396551 ]\n",
      " [-1.0865242 ]]\n",
      "64 Cost:  0.79612696 \n",
      "Prediction:\n",
      " [[ 0.47501874]\n",
      " [ 0.23437989]\n",
      " [-0.15192747]\n",
      " [-0.56238663]\n",
      " [-0.31488878]\n",
      " [-0.42193115]\n",
      " [-1.039634  ]\n",
      " [-1.0865031 ]]\n",
      "65 Cost:  0.7960789 \n",
      "Prediction:\n",
      " [[ 0.47505653]\n",
      " [ 0.23441803]\n",
      " [-0.15189505]\n",
      " [-0.5623609 ]\n",
      " [-0.3148591 ]\n",
      " [-0.42190218]\n",
      " [-1.039613  ]\n",
      " [-1.086482  ]]\n",
      "66 Cost:  0.7960309 \n",
      "Prediction:\n",
      " [[ 0.47509432]\n",
      " [ 0.2344563 ]\n",
      " [-0.15186274]\n",
      " [-0.5623352 ]\n",
      " [-0.31482935]\n",
      " [-0.42187333]\n",
      " [-1.0395919 ]\n",
      " [-1.0864608 ]]\n",
      "67 Cost:  0.79598284 \n",
      "Prediction:\n",
      " [[ 0.47513223]\n",
      " [ 0.23449445]\n",
      " [-0.15183043]\n",
      " [-0.5623095 ]\n",
      " [-0.31479955]\n",
      " [-0.42184436]\n",
      " [-1.0395709 ]\n",
      " [-1.0864397 ]]\n",
      "68 Cost:  0.7959348 \n",
      "Prediction:\n",
      " [[ 0.47517002]\n",
      " [ 0.2345326 ]\n",
      " [-0.15179813]\n",
      " [-0.56228375]\n",
      " [-0.31476974]\n",
      " [-0.4218154 ]\n",
      " [-1.0395498 ]\n",
      " [-1.0864186 ]]\n",
      "69 Cost:  0.7958869 \n",
      "Prediction:\n",
      " [[ 0.4752078 ]\n",
      " [ 0.23457086]\n",
      " [-0.15176582]\n",
      " [-0.56225806]\n",
      " [-0.31474   ]\n",
      " [-0.42178655]\n",
      " [-1.0395288 ]\n",
      " [-1.0863975 ]]\n",
      "70 Cost:  0.7958388 \n",
      "Prediction:\n",
      " [[ 0.4752457 ]\n",
      " [ 0.23460901]\n",
      " [-0.15173352]\n",
      " [-0.56223243]\n",
      " [-0.31471026]\n",
      " [-0.42175758]\n",
      " [-1.0395077 ]\n",
      " [-1.0863763 ]]\n",
      "71 Cost:  0.7957908 \n",
      "Prediction:\n",
      " [[ 0.4752835 ]\n",
      " [ 0.23464715]\n",
      " [-0.1517011 ]\n",
      " [-0.56220675]\n",
      " [-0.31468046]\n",
      " [-0.42172873]\n",
      " [-1.0394866 ]\n",
      " [-1.0863552 ]]\n",
      "72 Cost:  0.79574275 \n",
      "Prediction:\n",
      " [[ 0.4753213 ]\n",
      " [ 0.23468542]\n",
      " [-0.15166879]\n",
      " [-0.562181  ]\n",
      " [-0.31465065]\n",
      " [-0.42169976]\n",
      " [-1.0394657 ]\n",
      " [-1.0863341 ]]\n",
      "73 Cost:  0.79569477 \n",
      "Prediction:\n",
      " [[ 0.47535908]\n",
      " [ 0.23472357]\n",
      " [-0.15163648]\n",
      " [-0.5621553 ]\n",
      " [-0.3146209 ]\n",
      " [-0.42167085]\n",
      " [-1.0394447 ]\n",
      " [-1.086313  ]]\n",
      "74 Cost:  0.7956467 \n",
      "Prediction:\n",
      " [[ 0.47539687]\n",
      " [ 0.23476171]\n",
      " [-0.15160418]\n",
      " [-0.5621296 ]\n",
      " [-0.31459117]\n",
      " [-0.421642  ]\n",
      " [-1.0394236 ]\n",
      " [-1.0862918 ]]\n",
      "75 Cost:  0.7955987 \n",
      "Prediction:\n",
      " [[ 0.47543478]\n",
      " [ 0.23479998]\n",
      " [-0.15157187]\n",
      " [-0.5621039 ]\n",
      " [-0.31456143]\n",
      " [-0.42161304]\n",
      " [-1.0394025 ]\n",
      " [-1.0862707 ]]\n",
      "76 Cost:  0.7955507 \n",
      "Prediction:\n",
      " [[ 0.47547257]\n",
      " [ 0.23483813]\n",
      " [-0.15153956]\n",
      " [-0.5620782 ]\n",
      " [-0.31453162]\n",
      " [-0.42158413]\n",
      " [-1.0393815 ]\n",
      " [-1.0862496 ]]\n",
      "77 Cost:  0.7955028 \n",
      "Prediction:\n",
      " [[ 0.47551036]\n",
      " [ 0.23487628]\n",
      " [-0.15150726]\n",
      " [-0.5620525 ]\n",
      " [-0.31450188]\n",
      " [-0.42155522]\n",
      " [-1.0393605 ]\n",
      " [-1.0862285 ]]\n",
      "78 Cost:  0.79545474 \n",
      "Prediction:\n",
      " [[ 0.47554827]\n",
      " [ 0.23491454]\n",
      " [-0.15147495]\n",
      " [-0.56202686]\n",
      " [-0.31447208]\n",
      " [-0.42152625]\n",
      " [-1.0393394 ]\n",
      " [-1.0862074 ]]\n",
      "79 Cost:  0.7954067 \n",
      "Prediction:\n",
      " [[ 0.47558606]\n",
      " [ 0.23495257]\n",
      " [-0.15144265]\n",
      " [-0.5620011 ]\n",
      " [-0.31444234]\n",
      " [-0.4214974 ]\n",
      " [-1.0393183 ]\n",
      " [-1.0861862 ]]\n",
      "80 Cost:  0.7953588 \n",
      "Prediction:\n",
      " [[ 0.47562385]\n",
      " [ 0.23499084]\n",
      " [-0.15141034]\n",
      " [-0.5619754 ]\n",
      " [-0.31441253]\n",
      " [-0.4214685 ]\n",
      " [-1.0392973 ]\n",
      " [-1.0861651 ]]\n",
      "81 Cost:  0.7953107 \n",
      "Prediction:\n",
      " [[ 0.47566164]\n",
      " [ 0.23502898]\n",
      " [-0.15137792]\n",
      " [-0.56194973]\n",
      " [-0.3143828 ]\n",
      " [-0.4214396 ]\n",
      " [-1.0392762 ]\n",
      " [-1.086144  ]]\n",
      "82 Cost:  0.7952627 \n",
      "Prediction:\n",
      " [[ 0.47569942]\n",
      " [ 0.23506725]\n",
      " [-0.15134561]\n",
      " [-0.561924  ]\n",
      " [-0.314353  ]\n",
      " [-0.42141068]\n",
      " [-1.0392553 ]\n",
      " [-1.0861229 ]]\n",
      "83 Cost:  0.7952147 \n",
      "Prediction:\n",
      " [[ 0.47573733]\n",
      " [ 0.2351054 ]\n",
      " [-0.1513133 ]\n",
      " [-0.5618983 ]\n",
      " [-0.3143233 ]\n",
      " [-0.4213817 ]\n",
      " [-1.0392342 ]\n",
      " [-1.0861018 ]]\n",
      "84 Cost:  0.79516673 \n",
      "Prediction:\n",
      " [[ 0.47577512]\n",
      " [ 0.23514354]\n",
      " [-0.151281  ]\n",
      " [-0.5618726 ]\n",
      " [-0.3142935 ]\n",
      " [-0.42135286]\n",
      " [-1.0392132 ]\n",
      " [-1.0860806 ]]\n",
      "85 Cost:  0.7951187 \n",
      "Prediction:\n",
      " [[ 0.4758129 ]\n",
      " [ 0.23518181]\n",
      " [-0.15124857]\n",
      " [-0.561847  ]\n",
      " [-0.31426376]\n",
      " [-0.4213239 ]\n",
      " [-1.0391921 ]\n",
      " [-1.0860595 ]]\n",
      "86 Cost:  0.79507077 \n",
      "Prediction:\n",
      " [[ 0.47585082]\n",
      " [ 0.23521996]\n",
      " [-0.15121627]\n",
      " [-0.5618212 ]\n",
      " [-0.31423402]\n",
      " [-0.42129493]\n",
      " [-1.0391711 ]\n",
      " [-1.0860384 ]]\n",
      "87 Cost:  0.7950227 \n",
      "Prediction:\n",
      " [[ 0.4758886 ]\n",
      " [ 0.23525822]\n",
      " [-0.15118396]\n",
      " [-0.56179553]\n",
      " [-0.31420422]\n",
      " [-0.42126608]\n",
      " [-1.03915   ]\n",
      " [-1.0860173 ]]\n",
      "88 Cost:  0.7949748 \n",
      "Prediction:\n",
      " [[ 0.4759264 ]\n",
      " [ 0.23529625]\n",
      " [-0.15115166]\n",
      " [-0.56176984]\n",
      " [-0.3141744 ]\n",
      " [-0.4212371 ]\n",
      " [-1.039129  ]\n",
      " [-1.0859962 ]]\n",
      "89 Cost:  0.79492676 \n",
      "Prediction:\n",
      " [[ 0.4759642 ]\n",
      " [ 0.23533452]\n",
      " [-0.15111935]\n",
      " [-0.5617441 ]\n",
      " [-0.31414467]\n",
      " [-0.42120826]\n",
      " [-1.0391079 ]\n",
      " [-1.0859749 ]]\n",
      "90 Cost:  0.79487884 \n",
      "Prediction:\n",
      " [[ 0.47600198]\n",
      " [ 0.23537266]\n",
      " [-0.15108705]\n",
      " [-0.56171846]\n",
      " [-0.31411493]\n",
      " [-0.4211793 ]\n",
      " [-1.0390869 ]\n",
      " [-1.0859538 ]]\n",
      "91 Cost:  0.79483086 \n",
      "Prediction:\n",
      " [[ 0.4760399 ]\n",
      " [ 0.23541081]\n",
      " [-0.15105474]\n",
      " [-0.5616927 ]\n",
      " [-0.3140852 ]\n",
      " [-0.4211504 ]\n",
      " [-1.0390658 ]\n",
      " [-1.0859327 ]]\n",
      "92 Cost:  0.7947829 \n",
      "Prediction:\n",
      " [[ 0.47607768]\n",
      " [ 0.23544908]\n",
      " [-0.15102243]\n",
      " [-0.56166697]\n",
      " [-0.31405544]\n",
      " [-0.42112148]\n",
      " [-1.0390449 ]\n",
      " [-1.0859116 ]]\n",
      "93 Cost:  0.7947349 \n",
      "Prediction:\n",
      " [[ 0.47611547]\n",
      " [ 0.23548722]\n",
      " [-0.15099013]\n",
      " [-0.56164134]\n",
      " [-0.31402564]\n",
      " [-0.4210925 ]\n",
      " [-1.0390238 ]\n",
      " [-1.0858904 ]]\n",
      "94 Cost:  0.7946869 \n",
      "Prediction:\n",
      " [[ 0.47615337]\n",
      " [ 0.23552537]\n",
      " [-0.15095782]\n",
      " [-0.56161565]\n",
      " [-0.31399584]\n",
      " [-0.42106366]\n",
      " [-1.0390028 ]\n",
      " [-1.0858693 ]]\n",
      "95 Cost:  0.7946389 \n",
      "Prediction:\n",
      " [[ 0.47619116]\n",
      " [ 0.23556364]\n",
      " [-0.15092552]\n",
      " [-0.56158996]\n",
      " [-0.3139661 ]\n",
      " [-0.4210347 ]\n",
      " [-1.0389817 ]\n",
      " [-1.0858482 ]]\n",
      "96 Cost:  0.794591 \n",
      "Prediction:\n",
      " [[ 0.47622895]\n",
      " [ 0.23560178]\n",
      " [-0.15089321]\n",
      " [-0.5615642 ]\n",
      " [-0.31393635]\n",
      " [-0.4210058 ]\n",
      " [-1.0389607 ]\n",
      " [-1.0858271 ]]\n",
      "97 Cost:  0.794543 \n",
      "Prediction:\n",
      " [[ 0.47626674]\n",
      " [ 0.23563993]\n",
      " [-0.1508609 ]\n",
      " [-0.5615385 ]\n",
      " [-0.31390655]\n",
      " [-0.42097688]\n",
      " [-1.0389396 ]\n",
      " [-1.0858059 ]]\n",
      "98 Cost:  0.794495 \n",
      "Prediction:\n",
      " [[ 0.47630453]\n",
      " [ 0.2356782 ]\n",
      " [-0.15082848]\n",
      " [-0.5615128 ]\n",
      " [-0.31387675]\n",
      " [-0.42094797]\n",
      " [-1.0389185 ]\n",
      " [-1.0857848 ]]\n",
      "99 Cost:  0.79444706 \n",
      "Prediction:\n",
      " [[ 0.47634244]\n",
      " [ 0.23571634]\n",
      " [-0.1507963 ]\n",
      " [-0.5614871 ]\n",
      " [-0.313847  ]\n",
      " [-0.42091906]\n",
      " [-1.0388975 ]\n",
      " [-1.0857637 ]]\n",
      "100 Cost:  0.79439914 \n",
      "Prediction:\n",
      " [[ 0.47638023]\n",
      " [ 0.23575449]\n",
      " [-0.15076387]\n",
      " [-0.56146145]\n",
      " [-0.31381726]\n",
      " [-0.42089015]\n",
      " [-1.0388765 ]\n",
      " [-1.0857426 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777) # for reproducibility\n",
    "\n",
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = np.array(\n",
    "    [\n",
    "        [828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "        [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "        [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "        [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "        [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "        [819, 823, 1198100, 816, 820.450012],\n",
    "        [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "        [809.51001, 816.659973, 1398100, 804.539978, 809.559998],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# very important. It does not work without it.\n",
    "xy = min_max_scaler(xy)\n",
    "print(xy)\n",
    "\n",
    "'''\n",
    "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
    " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
    " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
    " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
    " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
    " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
    " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
    " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
    "'''\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]] #(n,1)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(101):\n",
    "        _, cost_val, hy_val = sess.run(\n",
    "            [train, cost, hypothesis], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
