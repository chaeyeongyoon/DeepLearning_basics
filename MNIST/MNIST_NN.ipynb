{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST softmax  \n",
    "tf.stop_gradient는 network의 특정 파트만 학습시키고 싶을 때 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001, Cost:5.007828803\n",
      "Epoch: 0011, Cost:0.480426253\n",
      "Epoch: 0021, Cost:0.358854970\n",
      "Epoch: 0031, Cost:0.310642639\n",
      "Epoch: 0041, Cost:0.285271341\n",
      "Learning Finished\n",
      "Accuracy: 0.9133\n",
      "Label: [2]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777) # for reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_iterations = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=hypothesis, labels=tf.stop_gradient(Y)\n",
    "        )\n",
    "    ) # Y는 변화시키지 않는다는 의미인거 같다\n",
    "\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for iteration in range(num_iterations):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val = sess.run([train, cost], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            avg_cost += cost_val / num_iterations\n",
    "        if epoch % 10 == 0:    \n",
    "            print(f'Epoch: {(epoch+1):04d}, Cost:{avg_cost:.9f}')\n",
    "        \n",
    "    print('Learning Finished')\n",
    "    \n",
    "    print(\n",
    "        'Accuracy:',\n",
    "        sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels})\n",
    "    )\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    print('Label:', sess.run(tf.argmax(mnist.test.labels[r : r + 1], axis=1)))\n",
    "    print(\n",
    "        'Prediction: ',\n",
    "        sess.run(\n",
    "            tf.argmax(hypothesis, axis=1), feed_dict={X:mnist.test.images[r : r + 1]}\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r : r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images[r].shape)\n",
    "print(mnist.test.images[r:r+1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST NN using ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost = 167.715418351\n",
      "Epoch: 0002 cost = 41.625966072\n",
      "Epoch: 0003 cost = 25.883558266\n",
      "Epoch: 0004 cost = 17.913293060\n",
      "Epoch: 0005 cost = 13.084635880\n",
      "Epoch: 0006 cost = 9.841317665\n",
      "Epoch: 0007 cost = 7.515251710\n",
      "Epoch: 0008 cost = 5.792110906\n",
      "Epoch: 0009 cost = 4.351602343\n",
      "Epoch: 0010 cost = 3.210373206\n",
      "Epoch: 0011 cost = 2.588291361\n",
      "Epoch: 0012 cost = 1.845477372\n",
      "Epoch: 0013 cost = 1.337907360\n",
      "Epoch: 0014 cost = 1.096201982\n",
      "Epoch: 0015 cost = 0.954828960\n",
      "Learning Finished!\n",
      "Accuracy: 0.9489\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST NN with xavier initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-2a4335b86656>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-2a4335b86656>:36: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "epoch: 1, cost = 0.626353765\n",
      "epoch: 2, cost = 0.370844680\n",
      "epoch: 3, cost = 0.330657038\n",
      "epoch: 4, cost = 0.310692821\n",
      "epoch: 5, cost = 0.296553750\n",
      "epoch: 6, cost = 0.289202777\n",
      "epoch: 7, cost = 0.281579395\n",
      "epoch: 8, cost = 0.279440072\n",
      "epoch: 9, cost = 0.276332269\n",
      "epoch: 10, cost = 0.271112303\n",
      "epoch: 11, cost = 0.273103824\n",
      "epoch: 12, cost = 0.270619915\n",
      "epoch: 13, cost = 0.272169657\n",
      "epoch: 14, cost = 0.269054319\n",
      "epoch: 15, cost = 0.267561109\n",
      "Learning Finished!\n",
      "Accuracy: 0.8661\n",
      "Label: [8]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.get_variable('W1', shape=[784, 256],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable('W2', shape=[256, 256],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable('W3', shape=[256, 10],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(f'epoch: {(epoch + 1)}, cost = {avg_cost:.9f}')\n",
    "    \n",
    "print('Learning Finished!')\n",
    "\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "            X:mnist.test.images, Y:mnist.test.labels}))\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print('Label:', sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print('Prediction: ', sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "            cmap='Greys', interpolation = 'nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0a37f1fd7f42>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-0a37f1fd7f42>:48: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 0.295805436\n",
      "Epoch: 0002 cost = 0.105303129\n",
      "Epoch: 0003 cost = 0.070806229\n",
      "Epoch: 0004 cost = 0.051644197\n",
      "Epoch: 0005 cost = 0.038861769\n",
      "Epoch: 0006 cost = 0.036012623\n",
      "Epoch: 0007 cost = 0.031401844\n",
      "Epoch: 0008 cost = 0.025491416\n",
      "Epoch: 0009 cost = 0.022702811\n",
      "Epoch: 0010 cost = 0.018646783\n",
      "Epoch: 0011 cost = 0.020761993\n",
      "Epoch: 0012 cost = 0.017793775\n",
      "Epoch: 0013 cost = 0.016838798\n",
      "Epoch: 0014 cost = 0.015925071\n",
      "Epoch: 0015 cost = 0.012351228\n",
      "Learning Finished!\n",
      "Accuracy: 0.9829\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), \n",
    "           cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep하지 않았을때보다 accuracy 낮음. 아마도 overfitting 때문일 듯 하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9ce86117f0d6>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-9ce86117f0d6>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-1-9ce86117f0d6>:55: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 0.463906071\n",
      "Epoch: 0002 cost = 0.170539091\n",
      "Epoch: 0003 cost = 0.132081525\n",
      "Epoch: 0004 cost = 0.106556593\n",
      "Epoch: 0005 cost = 0.094793432\n",
      "Epoch: 0006 cost = 0.084597523\n",
      "Epoch: 0007 cost = 0.077702280\n",
      "Epoch: 0008 cost = 0.068895308\n",
      "Epoch: 0009 cost = 0.064165776\n",
      "Epoch: 0010 cost = 0.060532868\n",
      "Epoch: 0011 cost = 0.056407073\n",
      "Epoch: 0012 cost = 0.050517340\n",
      "Epoch: 0013 cost = 0.052754798\n",
      "Epoch: 0014 cost = 0.050192165\n",
      "Epoch: 0015 cost = 0.048261437\n",
      "Learning Finished!\n",
      "Accuracy: 0.9823\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), \n",
    "           cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
