{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c494100ed9b2>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-c494100ed9b2>:58: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Learning started. It takes some time.\n",
      "Epoch: 0001 cost = 0.172275137\n",
      "Epoch: 0002 cost = 0.053160682\n",
      "Epoch: 0003 cost = 0.039079840\n",
      "Epoch: 0004 cost = 0.031074807\n",
      "Epoch: 0005 cost = 0.024511081\n",
      "Epoch: 0006 cost = 0.020179195\n",
      "Epoch: 0007 cost = 0.017512245\n",
      "Epoch: 0008 cost = 0.013928867\n",
      "Epoch: 0009 cost = 0.012356995\n",
      "Epoch: 0010 cost = 0.010902328\n",
      "Epoch: 0011 cost = 0.008495595\n",
      "Epoch: 0012 cost = 0.007186033\n",
      "Epoch: 0013 cost = 0.006043664\n",
      "Epoch: 0014 cost = 0.006678311\n",
      "Epoch: 0015 cost = 0.005488474\n",
      "Learning Finished!\n",
      "Accuracy: 0.9884\n",
      "Label:  [6]\n",
      "Prediction:  [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1]) # image input\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape = (? 28 28 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32]))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2,  1], padding='SAME')\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n",
    "'''\n",
    "\n",
    "# Final FC 7x7x64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning started. It takes some time.')\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-2-ff18aed77dea>:32: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.395631644\n",
      "Epoch: 0002 cost = 0.100661865\n",
      "Epoch: 0003 cost = 0.075600670\n",
      "Epoch: 0004 cost = 0.062804004\n",
      "Epoch: 0005 cost = 0.050919419\n",
      "Epoch: 0006 cost = 0.047242428\n",
      "Epoch: 0007 cost = 0.043256879\n",
      "Epoch: 0008 cost = 0.039943613\n",
      "Epoch: 0009 cost = 0.036423626\n",
      "Epoch: 0010 cost = 0.035575509\n",
      "Learning Finished!\n",
      "Accuracy: 0.9925\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Python Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-9511b340861f>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-9511b340861f>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-2-9511b340861f>:101: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.373789547\n",
      "Epoch: 0002 cost = 0.104020785\n",
      "Epoch: 0003 cost = 0.073269101\n",
      "Epoch: 0004 cost = 0.060911964\n",
      "Epoch: 0005 cost = 0.051267141\n",
      "Epoch: 0006 cost = 0.046819998\n",
      "Epoch: 0007 cost = 0.042509014\n",
      "Epoch: 0008 cost = 0.039538942\n",
      "Epoch: 0009 cost = 0.036113881\n",
      "Epoch: 0010 cost = 0.032963101\n",
      "Learning Finished!\n",
      "Accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "    \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout probability\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "            # input placeholders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28 x 28 x 1\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            \n",
    "            # L1 ImgIN shape = (?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            '''\n",
    "             # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            '''\n",
    "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            '''\n",
    "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "            '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.layers API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d405c63b4e47>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-d405c63b4e47>:36: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-d405c63b4e47>:39: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-d405c63b4e47>:41: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-1-d405c63b4e47>:62: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-d405c63b4e47>:71: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.292708064\n",
      "Epoch: 0002 cost = 0.091204992\n",
      "Epoch: 0003 cost = 0.066650655\n",
      "Epoch: 0004 cost = 0.056954494\n",
      "Epoch: 0005 cost = 0.050164891\n",
      "Epoch: 0006 cost = 0.046104122\n",
      "Epoch: 0007 cost = 0.039850314\n",
      "Epoch: 0008 cost = 0.038612692\n",
      "Epoch: 0009 cost = 0.036912648\n",
      "Epoch: 0010 cost = 0.031227465\n",
      "Learning Finished!\n",
      "Accuracy: 0.9931\n",
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            \n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            \n",
    "            # Conv layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3],\n",
    "                                     padding = 'SAME', activation=tf.nn.relu)\n",
    "            # Pool layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2,2], \n",
    "                                            padding='SAME', strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1, \n",
    "                                         rate=0.3, training=self.training) \n",
    "            # rate=drop , training: (boolean) training mode/inference mode\n",
    "            \n",
    "            # conv layer, pooling layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding = 'SAME', activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding='SAME', strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.3, training=self.training)\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n",
    "            \n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(m1.logits, 1), feed_dict={m1.X: mnist.test.images[r:r + 1], m1.training: 0}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113] *",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
