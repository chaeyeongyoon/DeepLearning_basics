{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0 2.5420997 [0.57387966]\n",
      "1 0.723086 [0.77273583]\n",
      "2 0.20567778 [0.87879246]\n",
      "3 0.058503903 [0.93535596]\n",
      "4 0.016641125 [0.9655232]\n",
      "5 0.0047334684 [0.9816124]\n",
      "6 0.0013464205 [0.99019325]\n",
      "7 0.0003829788 [0.99476975]\n",
      "8 0.00010893249 [0.99721056]\n",
      "9 3.098685e-05 [0.99851227]\n",
      "10 8.814037e-06 [0.99920654]\n",
      "11 2.507292e-06 [0.9995768]\n",
      "12 7.132302e-07 [0.9997743]\n",
      "13 2.029509e-07 [0.9998796]\n",
      "14 5.77155e-08 [0.9999358]\n",
      "15 1.6363018e-08 [0.9999658]\n",
      "16 4.6703263e-09 [0.99998176]\n",
      "17 1.3180177e-09 [0.9999903]\n",
      "18 3.746159e-10 [0.9999948]\n",
      "19 1.032987e-10 [0.99999726]\n",
      "20 3.1622704e-11 [0.9999985]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]),name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = W * X\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "# minimize cost: Gradient Descent using derivative: W -= Learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute gradient and apply gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ui88g\\anaconda3\\envs\\tf113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0 37.333332 [(37.333336, 4.6266665)]\n",
      "1 33.84889 [(33.84889, 4.2881775)]\n",
      "2 30.689657 [(30.689657, 3.9812808)]\n",
      "3 27.825287 [(27.825287, 3.703028)]\n",
      "4 25.228262 [(25.228262, 3.4507453)]\n",
      "5 22.873621 [(22.873623, 3.2220092)]\n",
      "6 20.738752 [(20.73875, 3.0146217)]\n",
      "7 18.803137 [(18.803137, 2.8265903)]\n",
      "8 17.048176 [(17.048176, 2.6561086)]\n",
      "9 15.457013 [(15.457014, 2.5015385)]\n",
      "10 14.014359 [(14.01436, 2.361395)]\n",
      "11 12.706352 [(12.706352, 2.2343314)]\n",
      "12 11.520427 [(11.520427, 2.119127)]\n",
      "13 10.445186 [(10.445185, 2.0146751)]\n",
      "14 9.470302 [(9.470302, 1.9199722)]\n",
      "15 8.586407 [(8.586407, 1.8341081)]\n",
      "16 7.785009 [(7.785009, 1.756258)]\n",
      "17 7.0584083 [(7.0584083, 1.685674)]\n",
      "18 6.399624 [(6.399624, 1.6216778)]\n",
      "19 5.8023257 [(5.8023252, 1.5636545)]\n",
      "20 5.260776 [(5.260776, 1.5110468)]\n",
      "21 4.7697697 [(4.7697697, 1.4633491)]\n",
      "22 4.324591 [(4.324591, 1.4201032)]\n",
      "23 3.9209633 [(3.9209635, 1.3808936)]\n",
      "24 3.5550067 [(3.5550067, 1.3453435)]\n",
      "25 3.2232056 [(3.2232056, 1.3131114)]\n",
      "26 2.9223735 [(2.9223735, 1.2838877)]\n",
      "27 2.6496189 [(2.6496186, 1.2573916)]\n",
      "28 2.4023216 [(2.4023216, 1.2333684)]\n",
      "29 2.178105 [(2.178105, 1.2115873)]\n",
      "30 1.9748148 [(1.9748147, 1.1918392)]\n",
      "31 1.7904993 [(1.7904994, 1.1739342)]\n",
      "32 1.623386 [(1.6233861, 1.1577003)]\n",
      "33 1.4718695 [(1.4718695, 1.1429816)]\n",
      "34 1.3344955 [(1.3344957, 1.1296366)]\n",
      "35 1.2099417 [(1.2099419, 1.1175373)]\n",
      "36 1.0970144 [(1.0970144, 1.1065671)]\n",
      "37 0.9946267 [(0.9946267, 1.0966209)]\n",
      "38 0.90179497 [(0.901795, 1.087603)]\n",
      "39 0.8176275 [(0.81762755, 1.0794266)]\n",
      "40 0.7413151 [(0.7413151, 1.0720135)]\n",
      "41 0.67212623 [(0.67212623, 1.0652922)]\n",
      "42 0.609394 [(0.609394, 1.0591983)]\n",
      "43 0.5525169 [(0.5525169, 1.0536731)]\n",
      "44 0.50094914 [(0.50094914, 1.0486636)]\n",
      "45 0.45419374 [(0.45419377, 1.0441216)]\n",
      "46 0.41180158 [(0.41180158, 1.0400037)]\n",
      "47 0.37336722 [(0.37336725, 1.03627)]\n",
      "48 0.33851996 [(0.33852, 1.0328848)]\n",
      "49 0.30692515 [(0.30692515, 1.0298156)]\n",
      "50 0.27827826 [(0.2782783, 1.0270327)]\n",
      "51 0.25230527 [(0.25230527, 1.0245097)]\n",
      "52 0.2287569 [(0.2287569, 1.022222)]\n",
      "53 0.20740573 [(0.20740573, 1.020148)]\n",
      "54 0.18804836 [(0.18804836, 1.0182675)]\n",
      "55 0.17049654 [(0.17049655, 1.0165626)]\n",
      "56 0.15458433 [(0.15458433, 1.0150168)]\n",
      "57 0.14015675 [(0.14015675, 1.0136153)]\n",
      "58 0.12707591 [(0.12707591, 1.0123445)]\n",
      "59 0.11521538 [(0.11521538, 1.0111923)]\n",
      "60 0.10446167 [(0.10446167, 1.0101477)]\n",
      "61 0.09471202 [(0.09471202, 1.0092006)]\n",
      "62 0.08587202 [(0.08587202, 1.0083419)]\n",
      "63 0.07785805 [(0.07785805, 1.0075634)]\n",
      "64 0.07059129 [(0.07059129, 1.0068574)]\n",
      "65 0.06400236 [(0.06400236, 1.0062174)]\n",
      "66 0.05802846 [(0.05802846, 1.005637)]\n",
      "67 0.052612226 [(0.052612226, 1.005111)]\n",
      "68 0.047702473 [(0.047702473, 1.0046339)]\n",
      "69 0.043249767 [(0.043249767, 1.0042014)]\n",
      "70 0.03921318 [(0.03921318, 1.0038093)]\n",
      "71 0.035553534 [(0.035553537, 1.0034539)]\n",
      "72 0.032236177 [(0.03223618, 1.0031315)]\n",
      "73 0.029227654 [(0.029227655, 1.0028392)]\n",
      "74 0.02649951 [(0.02649951, 1.0025742)]\n",
      "75 0.024025917 [(0.024025917, 1.002334)]\n",
      "76 0.021783749 [(0.02178375, 1.0021162)]\n",
      "77 0.01975123 [(0.019751232, 1.0019187)]\n",
      "78 0.017907381 [(0.017907381, 1.0017396)]\n",
      "79 0.016236702 [(0.016236704, 1.0015773)]\n",
      "80 0.014720838 [(0.014720838, 1.00143)]\n",
      "81 0.01334699 [(0.013346991, 1.0012965)]\n",
      "82 0.012100856 [(0.012100856, 1.0011755)]\n",
      "83 0.010971785 [(0.010971785, 1.0010659)]\n",
      "84 0.0099481745 [(0.0099481745, 1.0009663)]\n",
      "85 0.009018898 [(0.009018898, 1.0008761)]\n",
      "86 0.008176883 [(0.008176884, 1.0007943)]\n",
      "87 0.007413149 [(0.007413149, 1.0007201)]\n",
      "88 0.006721576 [(0.006721576, 1.0006529)]\n",
      "89 0.0060940585 [(0.0060940585, 1.000592)]\n",
      "90 0.005525271 [(0.0055252714, 1.0005368)]\n",
      "91 0.0050098896 [(0.0050098896, 1.0004867)]\n",
      "92 0.004542589 [(0.004542589, 1.0004413)]\n",
      "93 0.0041189194 [(0.0041189194, 1.0004001)]\n",
      "94 0.0037339528 [(0.003733953, 1.0003628)]\n",
      "95 0.0033854644 [(0.0033854644, 1.0003289)]\n",
      "96 0.0030694802 [(0.0030694804, 1.0002983)]\n",
      "97 0.0027837753 [(0.0027837753, 1.0002704)]\n",
      "98 0.0025234222 [(0.0025234222, 1.0002451)]\n",
      "99 0.0022875469 [(0.0022875469, 1.0002222)]\n",
      "100 0.0020739238 [(0.0020739238, 1.0002015)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# Manual gradient\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize: Gradient Descent Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# Get gradients\n",
    "gvs = optimizer.compute_gradients(cost)\n",
    "\n",
    "# Optional: modify gradient if necessary\n",
    "# gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "\n",
    "# Apply gradients\n",
    "# gvs에 다른값 넣어도 됨. 다른 gradients를 적용 가능\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(101):\n",
    "        gradient_val, gvs_val, _ = sess.run([gradient, gvs, apply_gradients])\n",
    "        print(step, gradient_val, gvs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
